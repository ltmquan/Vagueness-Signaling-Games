{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import tomllib as tml\n",
    "import numpy as np\n",
    "import display_helper as dh\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options looks like:\n",
    "```\n",
    "options = {\n",
    "    \"WLSACCESSID\": \"********-****-****-****-************\",\n",
    "    \"WLSSECRET\": \"********-****-****-****-************\",\n",
    "    \"LICENSEID\": _____,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gurobi credentials\n",
    "options = tml.load(open(\"license.toml\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish env (must close)\n",
    "env = gp.Env(params=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with MPS File\n",
    "I made a MPS file by solving LP.mod (written by Quan Luu) with GLPK for Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.read(\"model.mps\", env=env)\n",
    "m.reset()\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure this tells us much. Check `glpk_out.txt`, it has the full output of this solution. \n",
    "Notable slice:\n",
    "```\n",
    "730 rows, 729 columns, 2160 non-zeros\n",
    "      0: obj =  -4.657500000e-01 inf =   1.000e+01 (2)\n",
    "      5: obj =  -1.523000000e-01 inf =   0.000e+00 (0)\n",
    "*   224: obj =   6.790500000e-01 inf =   2.065e-14 (0) 1\n",
    "OPTIMAL LP SOLUTION FOUND\n",
    "Integer optimization begins...\n",
    "Long-step dual simplex will be used\n",
    "+   224: mip =     not found yet <=              +inf        (1; 0)\n",
    "+   224: >>>>>   6.790500000e-01 <=   6.790500000e-01   0.0% (1; 0)\n",
    "+   224: mip =   6.790500000e-01 <=     tree is empty   0.0% (0; 1)\n",
    "INTEGER OPTIMAL SOLUTION FOUND\n",
    "Time used:   0.0 secs\n",
    "Memory used: 1.9 Mb (1980226 bytes)\n",
    "STATES:\n",
    "[1 2 3]   [10 11 12]   [19 20 21]\n",
    "[4 5 6] , [13 14 15] , [22 23 24].\n",
    "[7 8 9]   [16 17 18]   [25 26 27]\n",
    "\n",
    "BUCKETS:\n",
    "Bucket 5: 1 2 3 4 5 6 7 8 9\n",
    "Bucket 11: 11 12 19 21\n",
    "Bucket 13: 10 13\n",
    "Bucket 14: 14 15\n",
    "Bucket 17: 16 17 18 25 26 27\n",
    "Bucket 23: 20 22 23 24\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setup\n",
    "I'm going to try and convert this outright to a Gurobi model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish model (must close)\n",
    "model = gp.Model(env=env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normpdf(x: float, mean: float, std: float) -> float:\n",
    "  var = float(std)**2\n",
    "  denom = (2*np.pi*var)**.5\n",
    "  num = np.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "  return num/denom\n",
    "\n",
    "def highlow(ind):\n",
    "  if ind == 0 or ind == 2:\n",
    "    return 0.4\n",
    "  else:\n",
    "    return 0.2\n",
    "\n",
    "def gen_state_prob(num_traits: int, num_states: int):\n",
    "  mean = (num_states-1) / 2\n",
    "  std = mean / 1.25\n",
    "\n",
    "  state_prob = np.zeros(tuple([num_states] * num_traits), dtype=np.float64)\n",
    "  for inds in np.ndindex(state_prob.shape):\n",
    "    prob = 1\n",
    "    for ind in inds:\n",
    "      prob *= normpdf(ind, mean, std)\n",
    "      # prob *= highlow(ind)\n",
    "    \n",
    "    state_prob[inds] = prob\n",
    "\n",
    "  state_prob = state_prob / np.sum(state_prob)\n",
    "\n",
    "  return state_prob.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the reward matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnumerize(num_traits: int, num_states: int, action: int):\n",
    "  ufaction = []\n",
    "  while action > 0:\n",
    "    ufaction.insert(0, action % num_states)\n",
    "    action = action // num_states\n",
    "\n",
    "  while len(ufaction) < num_traits:\n",
    "    ufaction.insert(0, 0)\n",
    "\n",
    "  return ufaction\n",
    "\n",
    "def reward_fn(param: tuple[float, float], state, action):\n",
    "  \n",
    "  l1dist = 0\n",
    "  for s, a in zip(state, action):\n",
    "    l1dist += abs(s - a)\n",
    "\n",
    "  return param[0] - param[1] * l1dist\n",
    "\n",
    "def reward_matrix(num_traits: int, num_states: int, reward_param: tuple[float, float]):\n",
    "  total_states = num_states**num_traits\n",
    "  res = np.array([[0 for _ in range(total_states)] for _ in range(total_states)], dtype=np.float64)\n",
    "  for x in range(total_states):\n",
    "    for y in range(total_states):\n",
    "      s1 = unnumerize(num_traits, num_states, x)\n",
    "      s2 = unnumerize(num_traits, num_states, y)\n",
    "\n",
    "      res[x, y] = reward_fn(reward_param, s1, s2)\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the neighbor list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_adj(num_traits: int, num_states: int, i: int, j: int):\n",
    "  s1 = unnumerize(num_traits, num_states, i)\n",
    "  s2 = unnumerize(num_traits, num_states, j)\n",
    "\n",
    "  l1dist = 0\n",
    "  for s, a in zip(s1, s2):\n",
    "    l1dist += abs(s - a)\n",
    "\n",
    "  return l1dist == 1\n",
    "\n",
    "def neighbor_lst(num_traits: int, num_states: int):\n",
    "  total_states = num_states**num_traits\n",
    "  res = [[] for _ in range(total_states)]\n",
    "  for x in range(total_states):\n",
    "    for y in range(x, total_states):\n",
    "      if is_adj(num_traits, num_states, x, y):\n",
    "        res[x].append(y)\n",
    "        res[y].append(x)\n",
    "\n",
    "  return res\n",
    "\n",
    "# def adj_matrix(num_traits: int, num_states: int):\n",
    "#   total_states = num_states**num_traits\n",
    "#   res = np.array([[0 for _ in range(total_states)] for _ in range(total_states)])\n",
    "#   for x in range(total_states):\n",
    "#     for y in range(total_states):\n",
    "#       res[x, y] = 1 if is_adj(num_traits, num_states, x, y) else 0\n",
    "\n",
    "#   return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "t = 3\n",
    "n_per_t = 6\n",
    "n = n_per_t**t\n",
    "k = 6\n",
    "reward_param = (1, 0.5)\n",
    "\n",
    "V = np.asarray([i for i in range(n)])\n",
    "\n",
    "state_prob = gen_state_prob(t, n_per_t)\n",
    "# state_prob = np.full(n, 1/n, dtype=np.float64)\n",
    "\n",
    "reward = reward_matrix(t, n_per_t, reward_param)\n",
    "\n",
    "neighbor = neighbor_lst(t, n_per_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hess variables\n",
    "# x[i, j] = 1 iff state i is in bucket j\n",
    "# NOTE: \"bucket j\" means that action j is played in that bucket\n",
    "x = model.addVars(V, V, vtype=GRB.BINARY)\n",
    "\n",
    "# cut egde variables\n",
    "# y[i, j] = 1 iff edge {i, j} is cut\n",
    "y = model.addVars(V, V, vtype=GRB.BINARY)\n",
    "\n",
    "# flow variables\n",
    "# f[i, j] = the flow from state i to state j\n",
    "f = model.addVars(V, V)\n",
    "\n",
    "# coverted x variables\n",
    "cx = model.addVars(V, V, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "# weighted x\n",
    "wx = model.addVars(V, V, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "# normalization ratio variables\n",
    "norm_ratio = model.addVars(V, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "# prob[state | sig] variable\n",
    "prob = model.addVars(V, V, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "# prob[state | sig] / prob[state] variable\n",
    "probdiff = model.addVars(V, V, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "# converted probdiff variables\n",
    "cprobdiff = model.addVars(V, V, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "# log(prob[state | sig] / prob[state]) variable\n",
    "log = model.addVars(V, V, vtype=GRB.CONTINUOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state objective\n",
    "# GPL: maximize EP: sum{i in V} PROB[i] * sum{j in V} x[i, j] * REWARD[i, j];\n",
    "# gp.quicksum( prob[i] * x[i][j] * reward[i][j] for i in V for j in V )\n",
    "\n",
    "# # payoff with min cut edge\n",
    "objective = gp.quicksum( gp.quicksum( (state_prob[i] * x[i,j] * reward[i][j]) for j in V) for i in V ) / n * (n**2 + 1) * 1000 - gp.quicksum( y[i, j] for i in V for j in V )\n",
    "\n",
    "# # payoff\n",
    "# objective = gp.quicksum( gp.quicksum( (state_prob[i] * x[i,j] * reward[i][j]) for j in V) for i in V ) / n\n",
    "\n",
    "# # info measure\n",
    "# objective = gp.quicksum( gp.quicksum( prob[i,j] * log[i,j] for j in V) for i in V)\n",
    "\n",
    "model.setObjective(objective, GRB.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constraints\n",
    "\n",
    "# /* there are exactly k buckets */\n",
    "# kBucketConstr: sum{j in V} x[j, j] = k;\n",
    "k_bucket = gp.quicksum( (x[j,j]) for j in V ) == k\n",
    "model.addConstr(k_bucket)\n",
    "\n",
    "# /* a state can only belong to one bucket */\n",
    "# uniqueBucketConstr{i in V}: sum{j in V} x[i, j] = 1;\n",
    "unique_bucket = ( gp.quicksum( (x[i,j]) for j in V ) == 1 for i in V )\n",
    "model.addConstrs(unique_bucket)\n",
    "\n",
    "# /* a state cannot belong to a non-existant bucket */\n",
    "# nonexBucketConstr{i in V, j in V}: x[i, j] <= x[j, j];\n",
    "nonex_bucket = ( (x[i,j] <= x[j,j]) for i in V for j in V )\n",
    "model.addConstrs(nonex_bucket)\n",
    "\n",
    "model.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add constraints for flow\n",
    "M = n - k + 1\n",
    "\n",
    "# /* cut edge constraints */\n",
    "# edge {i, j} is cut if i and j are not adjacent.\n",
    "cut_edge_not_adj = ( y[i, j] == 1 for i in V for j in np.setdiff1d(V, np.array(neighbor[i])) )\n",
    "model.addConstrs(cut_edge_not_adj)\n",
    "\n",
    "# edge {i, j} is cut if i and j are in different buckets.\n",
    "cut_edge_diff_bucket = ( y[i, j] >= x[i, l] - x[j, l] for i in V for j in V for l in V)\n",
    "model.addConstrs(cut_edge_diff_bucket)\n",
    "\n",
    "# do not send flow across cut edges\n",
    "cut_edge_flow = ( f[i, j] + f[j, i] <= M * (1 - y[i, j]) for i in V for j in V )\n",
    "model.addConstrs(cut_edge_flow)\n",
    "\n",
    "# /* flow constraint */\n",
    "# if not a root, consume some flow.\n",
    "# if a root, only send out (so much) flow.\n",
    "flow = ( gp.quicksum( f[j, i]- f[i, j] for j in neighbor[i] )\n",
    "      >= 1 - M * x[i, i] for i in V )\n",
    "model.addConstrs(flow)\n",
    "\n",
    "model.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add constraints for info measure\n",
    "\n",
    "# # converted x constraint\n",
    "# small_val_constr_1 = (cx[i, j] <= x[j, j] * (x[i, j] + 1e-7)  for i in V for j in V)\n",
    "# model.addConstrs(small_val_constr_1)\n",
    "\n",
    "# small_val_constr_2 = (cx[i, j] >= x[j, j] * (1e-7) for i in V for j in V)\n",
    "# model.addConstrs(small_val_constr_2)\n",
    "\n",
    "# sum_cx_constr = ( gp.quicksum( cx[i, j] for j in V ) == 1 for i in V)\n",
    "# model.addConstrs(sum_cx_constr)\n",
    "\n",
    "# # weighted x constraint\n",
    "# wx_constr = ( wx[i, j] == cx[i, j] * state_prob[i] for i in V for j in V)\n",
    "# model.addConstrs(wx_constr)\n",
    "\n",
    "# # normalization ratio constraint\n",
    "# # norm_ratio_constr = ( norm_ratio[j] * gp.quicksum(wx[i, j] for i in V) == x[j, j] for j in V )\n",
    "# norm_ratio_constr = ( norm_ratio[j] * gp.quicksum(cx[i, j] for i in V) == x[j, j] for j in V )\n",
    "# model.addConstrs(norm_ratio_constr)\n",
    "\n",
    "# norm_ratio_zero = ( norm_ratio[j] * x[j, j] == norm_ratio[j] for j in V )\n",
    "# model.addConstrs(norm_ratio_zero)\n",
    "\n",
    "# # prob[state | sig] constraint\n",
    "# # prob_constr = ( prob[i, j] == wx[i, j] * norm_ratio[j] for i in V for j in V )\n",
    "# prob_constr = ( prob[i, j] == cx[i, j] * norm_ratio[j] for i in V for j in V )\n",
    "# model.addConstrs(prob_constr)\n",
    "\n",
    "# # prob(state | sig) / prob(state) constraint\n",
    "# probdiff_constr = ( probdiff[i, j] == prob[i, j] / state_prob[i] for i in V for j in V )\n",
    "# model.addConstrs(probdiff_constr)\n",
    "\n",
    "# # converted probdiff constraint\n",
    "# cprobdiff_constr = ( cprobdiff[i, j] == gp.max_(probdiff[i, j], constant=1) for i in V for j in V )\n",
    "# model.addConstrs(cprobdiff_constr)\n",
    "\n",
    "# # log(prob[state | sig] / prob[state]) variable\n",
    "# for i in V:\n",
    "#   for j in V:\n",
    "#     model.addGenConstrLog(cprobdiff[i, j], log[i, j])\n",
    "\n",
    "# model.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test constraints\n",
    "# for i in range(24):\n",
    "#   model.addConstrs(x[i, j] == x[i+1, j] for j in V)\n",
    "\n",
    "# model.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple solutions\n",
    "model.Params.PoolSolutions = 1\n",
    "model.Params.PoolSearchMode = 2\n",
    "\n",
    "model.update()\n",
    "\n",
    "# can we solve?\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing\n",
    "# for i in V:\n",
    "#   print([f\"{x[i,j].getAttr(\"X\"):.1f}\" for j in V])\n",
    "# print()\n",
    "# for i in V:\n",
    "#   print([cx[i,j].getAttr(\"X\") for j in V])\n",
    "# print()\n",
    "# for i in V:\n",
    "#   print([wx[i,j].getAttr(\"X\") for j in V])\n",
    "# print()\n",
    "# print([norm_ratio[i].getAttr(\"X\") for i in V])\n",
    "# print()\n",
    "# for i in V:\n",
    "#   print([f\"{prob[i,j].getAttr(\"X\"):.2f}\" for j in V])\n",
    "# print()\n",
    "# for i in V:\n",
    "#   print([f\"{cprobdiff[i,j].getAttr(\"X\"):.2f}\" for j in V])\n",
    "# print()\n",
    "# for i in V:\n",
    "#   print([log[i,j].getAttr(\"X\") for j in V])\n",
    "# print()\n",
    "\n",
    "# test = 0\n",
    "# for i in V:\n",
    "#   for j in V:\n",
    "#     test += prob[i, j].getAttr(\"X\") * log[i, j].getAttr(\"X\")\n",
    "\n",
    "# print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Extraction\n",
    "This was a little easier than I thought, thanks to Quan's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = [j for j in V if round(x[j,j].getAttr(\"x\")) == 1]\n",
    "bucket_lookup = dict()\n",
    "\n",
    "for ind, j in enumerate(centers):\n",
    "    print(f\"Bucket {j+1}: \", end=\"\")\n",
    "    members = [i for i in V if round(x[i,j].getAttr(\"x\")) == 1]\n",
    "    for i in members:\n",
    "        print(f\"{i+1} \", end=\"\")\n",
    "        bucket_lookup[i] = ind\n",
    "    print()\n",
    "\n",
    "og_cube, legend = dh.cube_from_lookup(bucket_lookup, n_per_t, centers)\n",
    "dh.show(og_cube, legend)\n",
    "\n",
    "cube = deepcopy(og_cube)\n",
    "\n",
    "cube = dh.rotate_aboutX(cube)\n",
    "dh.show(cube, legend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "STATES:\n",
    "[1  2  3  4  5]    [26 27 28 29 30]   [51 52 53 54 55]\n",
    "[6  7  8  9  10]   [31 32 33 34 35]   [56 57 58 59 60]\n",
    "[11 12 13 14 15] , [36 37 38 39 40] , [61 62 63 64 65] ,\n",
    "[16 17 18 19 20]   [41 42 43 44 45]   [66 67 68 69 70]\n",
    "[21 22 23 24 25]   [46 47 48 49 50]   [71 72 73 74 75]\n",
    "\n",
    "[76 77 78 79 80]   [101 102 103 104 105]\n",
    "[81 82 83 84 85]   [106 107 108 109 110]\n",
    "[86 87 88 89 90] , [111 112 113 114 115]\n",
    "[91 92 93 94 95]   [116 117 118 119 120]\n",
    "[96 97 98 99 100]  [121 122 123 124 125]\n",
    "\n",
    "```\n",
    "\n",
    "<!-- BUCKETS:\n",
    "Bucket 5: 1 2 3 4 5 6 7 8 9\n",
    "Bucket 11: 11 12 19 21\n",
    "Bucket 13: 10 13\n",
    "Bucket 14: 14 15\n",
    "Bucket 17: 16 17 18 25 26 27\n",
    "Bucket 23: 20 22 23 24\n",
    "\n",
    "GLPK Output again for comparison. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert strategy to calculate information content measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(num_traits, num_states, num_signals, strat):\n",
    "  total_states = num_states**num_traits\n",
    "  small_val = 1e-7\n",
    "  large_val = 1 - (small_val * (num_signals-1))\n",
    "\n",
    "  signal_strat = np.full((num_signals, total_states), small_val, dtype=np.float64)\n",
    "\n",
    "  for i, bucket in enumerate(strat):\n",
    "    for state in bucket:\n",
    "      signal_strat[i, state] = large_val\n",
    "\n",
    "  return signal_strat\n",
    "\n",
    "def info_measure(num_traits, num_states, num_signals, signal_prob, weighted=True) -> float:\n",
    "    \"\"\"Calculates the information content of the signals\n",
    "\n",
    "    Args:\n",
    "      signal_prob (np.ndarray): the probabilities of the signals\n",
    "      weighted (boolean): weighted/unweighted options\n",
    "\n",
    "    Returns:\n",
    "      inf (float): total information content measure\n",
    "      inf_sigs (list): information content by signal\n",
    "      inf_states (list): information content by state\n",
    "    \"\"\"\n",
    "    total_states = num_states**num_traits\n",
    "    signal_prob = signal_prob.reshape(num_signals, total_states)\n",
    "\n",
    "    prob = np.zeros_like(signal_prob)\n",
    "    for i in range(num_signals):\n",
    "      for j in range(total_states):\n",
    "        prob[i, j] = signal_prob[i, j] * state_prob[j]\n",
    "    prob_sig = [np.sum(prob[i]) for i in range(num_signals)]\n",
    "    prob = (prob.T / np.sum(prob, axis=1)).T\n",
    "\n",
    "    inf = 0\n",
    "    inf_sigs = []\n",
    "    inf_states = []\n",
    "    for i in range(num_signals):\n",
    "      inf_sig = 0\n",
    "      inf_states.append([])\n",
    "      for j in range(total_states):\n",
    "        inf_state = prob[i, j] * np.log(prob[i, j]/state_prob[j])\n",
    "        inf_sig += inf_state\n",
    "        \n",
    "        if weighted:\n",
    "          inf_state = prob_sig[i] * inf_state\n",
    "\n",
    "        inf_states[i].append(inf_state)\n",
    "\n",
    "      if weighted:\n",
    "        inf_sig = prob_sig[i] * inf_sig\n",
    "\n",
    "      inf_sigs.append(inf_sig)\n",
    "      inf += inf_sig\n",
    "\n",
    "    new_size = [num_signals]\n",
    "    new_size.extend([num_states] * num_traits)\n",
    "    inf_states = np.resize(np.array(inf_states), tuple(new_size))\n",
    "\n",
    "    return inf, inf_sigs, inf_states\n",
    "\n",
    "def stats(inf, inf_sigstates):\n",
    "  inf_states = np.sum(inf_sigstates, axis=0)\n",
    "\n",
    "  print(f\"Info measure = {inf}\")\n",
    "  print(f\"Info measure by states:\")\n",
    "\n",
    "  for t1 in inf_states:\n",
    "    for t2 in t1:\n",
    "      for t3 in t2:\n",
    "        print(f\"{t3:.3f}\", end=\" \")\n",
    "      print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the average information content measure of all n results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n solutions\n",
    "n_solutions = model.getAttr(\"SolCount\")\n",
    "print(f\"Number of solutions: {n_solutions}\")\n",
    "\n",
    "new_size = [k]\n",
    "new_size.extend([n_per_t] * t)\n",
    "\n",
    "total_info = 0\n",
    "total_info_sigstates = np.zeros(tuple(new_size))\n",
    "total_w_info = 0\n",
    "total_w_info_sigstates = np.zeros(tuple(new_size))\n",
    "\n",
    "for sol in range(0, n_solutions):\n",
    "    model.params.SolutionNumber = sol\n",
    "    print(f\"Solution {sol+1}\")\n",
    "    centers = [j for j in V if round(x[j,j].getAttr(\"Xn\")) == 1]\n",
    "    strat = []\n",
    "    for j in centers:\n",
    "        print(f\"Bucket {j+1}: \", end=\"\")\n",
    "        members = [i for i in V if round(x[i,j].getAttr(\"Xn\")) == 1]\n",
    "        for i in members:\n",
    "            print(f\"{i+1} \", end=\"\")\n",
    "        print()\n",
    "        strat.append(members)\n",
    "\n",
    "    converted_strat = convert(t, n_per_t, k, strat)\n",
    "        \n",
    "    inf, inf_sigs, inf_sigstates = info_measure(t, n_per_t, k, converted_strat, False)\n",
    "\n",
    "    print(f\"Info measure={inf}\")\n",
    "\n",
    "    w_inf, w_inf_sigs, w_inf_sigstates = info_measure(t, n_per_t, k, converted_strat)\n",
    "\n",
    "    total_info += inf\n",
    "    total_info_sigstates += inf_sigstates\n",
    "\n",
    "    total_w_info += w_inf\n",
    "    total_w_info_sigstates += w_inf_sigstates\n",
    "\n",
    "    \n",
    "avg_info = total_info / n_solutions\n",
    "avg_info_sigstates = total_info_sigstates / n_solutions\n",
    "avg_w_info = total_w_info / n_solutions\n",
    "avg_w_info_sigstates = total_w_info_sigstates / n_solutions\n",
    "\n",
    "print(f\"Objective = {model.ObjVal}\\n\")\n",
    "\n",
    "op = 0\n",
    "for i in V:\n",
    "    for j in V:\n",
    "        op += state_prob[i] * x[i,j].getAttr(\"X\") * reward[i][j]\n",
    "print(f\"Payoff = {op / n}\")\n",
    "\n",
    "# print(\"UNWEIGHTED\")\n",
    "# stats(avg_info, avg_info_sigstates)\n",
    "# print()\n",
    "# print(\"WEIGHTED\")\n",
    "# stats(avg_w_info, avg_w_info_sigstates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing these objects for best practice\n",
    "\n",
    "model.close()\n",
    "m.close()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
